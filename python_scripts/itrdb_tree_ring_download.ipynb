{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## geojson file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_path = \"https://www1.ncdc.noaa.gov/pub/data/metadata/published/paleo/json\"\n",
    "feature_collection = {\"type\":\"FeatureCollection\",\n",
    "                      \"features\": []}\n",
    "files = []\n",
    "with urllib.request.urlopen(root_path) as url:\n",
    "    html_doc = url.read()\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "conts = soup.body.table.contents\n",
    "\n",
    "for line in conts:\n",
    "    if line != '\\n':\n",
    "        fname = line.get_text()\n",
    "        if \"tree\" in fname:\n",
    "            record_name = fname[:fname.index('.json')] + \".json\"\n",
    "            full_path = root_path + \"/\" + record_name\n",
    "            with urllib.request.urlopen(full_path) as url:\n",
    "                json_doc_string = url.read()\n",
    "                json_doc = json.loads(json_doc_string)\n",
    "            orig_file = full_path\n",
    "            try:\n",
    "                study_id  = json_doc[\"NOAAStudyId\"]\n",
    "                study_code = json_doc[\"studyCode\"]\n",
    "                resource = json_doc['onlineResourceLink']\n",
    "                doi = json_doc[\"doi\"]\n",
    "                investigators = json_doc[\"investigators\"]\n",
    "                site_coords = json_doc['site'][0]['geo']['geometry']['coordinates']\n",
    "                full_data = json_doc['site'][0]['paleoData']\n",
    "                site_name = json_doc['site'][0]['siteName']\n",
    "                common_species = json_doc['site'][0]['paleoData'][0]['species'][0]['commonName']\n",
    "                scientific_species = json_doc['site'][0]['paleoData'][0]['species'][0]['scientificName']\n",
    "                code_species = json_doc['site'][0]['paleoData'][0]['species'][0]['speciesCode']\n",
    "                earliest_date = json_doc['site'][0]['paleoData'][0]['earliestYear']\n",
    "                most_recent_date = json_doc['site'][0]['paleoData'][0]['mostRecentYear']\n",
    "                \n",
    "                geojson = {\"type\": \"Feature\",\n",
    "                            \"geometry\": {\n",
    "                                \"type\": \"Point\",\n",
    "                                \"coordinates\": [site_coords[1], site_coords[0]]\n",
    "                              },\n",
    "                          \"properties\": {\n",
    "                              \"orig_filename\": orig_file,\n",
    "                              \"study_ID\": study_id,\n",
    "                              \"doi\": doi,\n",
    "                              \"investigators\": investigators,\n",
    "                              \"lat\": site_coords[0],\n",
    "                              \"lon\": site_coords[1],\n",
    "                              \"site_name\": site_name,\n",
    "                              \"species_name_com\": common_species,\n",
    "                              \"species_name_sci\": scientific_species,\n",
    "                              \"species_code\": code_species,\n",
    "                              \"earliest_year\": earliest_date,\n",
    "                              \"most_recent_year\": most_recent_date,\n",
    "                              \"data\": full_data,\n",
    "                              \"study_code\": study_code,\n",
    "                              \"noaa_online_resource_page\": resource\n",
    "                              }\n",
    "                        }\n",
    "                feature_collection[\"features\"].append(geojson)\n",
    "            except IndexError:\n",
    "                print(full_path)\n",
    "# do json encoding\n",
    "with open('./itrdb.geojson', 'w') as outfile:\n",
    "    json.dump(feature_collection, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_path = \"https://www1.ncdc.noaa.gov/pub/data/metadata/published/paleo/json\"\n",
    "feature_collection = {\"type\":\"FeatureCollection\",\n",
    "                      \"features\": []}\n",
    "files = []\n",
    "with urllib.request.urlopen(root_path) as url:\n",
    "    html_doc = url.read()\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "conts = soup.body.table.contents\n",
    "\n",
    "output_data_table_name = \"C:/Users/Jacob/Projects/itrdb/itrdb_chronology_data.txt\"\n",
    "data_table_file = open(output_data_table_name, \"w\")\n",
    "data_table_file.write(\"site_id\")\n",
    "data_file_thresh = 7\n",
    "var_thresh = 3\n",
    "for i in range(data_file_thresh): # 7 is arbitrary, (an assumption) I can't see there being more than 10 data files associated with a single site??\n",
    "    num  = \"0\" + str(i)\n",
    "    data_table_file.write(\",u_\"+num+\", u_\"+num+\"_desc, u_\"+num+\"_keyword\")\n",
    "    for v in range(var_thresh): # 3 is arbitrary, I can't see there being more than 3 variables\n",
    "        v_num = \"0\" + str(v)\n",
    "        data_table_file.write(\", v_\"+num+\"_\"+v_num+\"_desc, v_\"+num+\"_\"+v_num+\"_meth, v_\"+num+\"_\"+v_num+\"_det, v_\"+num+\"_\"+v_num+\"_unit\")\n",
    "data_table_file.write(\"\\n\")\n",
    "\n",
    "for line in conts:\n",
    "    if line != '\\n':\n",
    "        fname = line.get_text()\n",
    "        if \"tree\" in fname:\n",
    "            record_name = fname[:fname.index('.json')] + \".json\"\n",
    "            full_path = root_path + \"/\" + record_name\n",
    "            with urllib.request.urlopen(full_path) as url:\n",
    "                json_doc_string = url.read()\n",
    "                json_doc = json.loads(json_doc_string)\n",
    "            orig_file = full_path\n",
    "            try:\n",
    "                study_id  = json_doc[\"NOAAStudyId\"]\n",
    "                \n",
    "                # getting paleoData\n",
    "                data_table_file.write(study_id)\n",
    "                whole_line = \"\"\n",
    "                n = 0\n",
    "                while n < len(json_doc['site'][0]['paleoData'][0]['dataFile']):\n",
    "                    data_url = json_doc['site'][0]['paleoData'][0]['dataFile'][n][\"fileUrl\"]\n",
    "                    data_desc = json_doc['site'][0]['paleoData'][0]['dataFile'][n][\"urlDescription\"]\n",
    "                    keyword = json_doc['site'][0]['paleoData'][0]['dataFile'][n][\"NOAAKeywords\"][0].split(\">\")[-1]\n",
    "                    file_str = \",\" + data_url + \",\" + data_desc + \",\" + keyword\n",
    "                    var_str = \"\"\n",
    "                    v = 0\n",
    "                    while v < len(json_doc['site'][0]['paleoData'][0]['dataFile'][n][\"variables\"]):\n",
    "                        var_desc = str(json_doc['site'][0]['paleoData'][0]['dataFile'][n][\"variables\"][v][\"cvWhat\"].split(\">\")[-1])\n",
    "                        var_meth = str(json_doc['site'][0]['paleoData'][0]['dataFile'][n][\"variables\"][v][\"cvMethod\"])\n",
    "                        var_det = str(json_doc['site'][0]['paleoData'][0]['dataFile'][n][\"variables\"][v][\"cvDetail\"])\n",
    "                        var_unit = str(json_doc['site'][0]['paleoData'][0]['dataFile'][n][\"variables\"][v][\"cvUnit\"])\n",
    "                        if var_desc == \"null\" or var_desc == None or var_desc == \"None\":\n",
    "                            var_desc = \"\"\n",
    "                        if var_meth == \"null\" or var_meth == None or var_meth == \"None\":\n",
    "                            var_meth = \"\"\n",
    "                        if var_det == \"null\" or var_det == None or var_det == \"None\":\n",
    "                            var_det = \"\"\n",
    "                        if var_unit == \"null\" or var_unit == None or var_unit == \"None\":\n",
    "                            var_unit = \"\"\n",
    "                        var_str += \",\" + var_desc + \",\" + var_meth + \",\" + var_det + \",\" + var_unit\n",
    "                        v+=1\n",
    "                    if v < var_thresh: # if didn't get enough variables to fill the row\n",
    "                        extras_v = \", , , , \"\n",
    "                        extras_v*=(var_thresh - v)\n",
    "                        var_str += extras_v\n",
    "                    whole_line+=file_str + var_str\n",
    "                    n+=1\n",
    "                if n < data_file_thresh:\n",
    "                    extras = \", , , , , , , \"\n",
    "                    extras*=(data_file_thresh - n)\n",
    "                whole_line+=extras\n",
    "                data_table_file.write(whole_line + \"\\n\")\n",
    "            except IndexError:\n",
    "                print(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## geojson to shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from osgeo import ogr\n",
    "from osgeo import osr\n",
    "\n",
    "def geojson_to_shapefile(input_filename, output_filename):\n",
    "    contents = open(input_filename)\n",
    "    contents = contents.read()\n",
    "    data = json.loads(contents)\n",
    "    \n",
    "    # set up the shapefile driver\n",
    "    driver = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
    "    # create the data source\n",
    "    data_source = driver.CreateDataSource(output_filename)\n",
    "    # create the spatial reference, WGS84\n",
    "    srs = osr.SpatialReference()\n",
    "    srs.ImportFromEPSG(4326)\n",
    "    # create the layer\n",
    "    layer = data_source.CreateLayer(\"itrdb\", srs, ogr.wkbPoint)\n",
    "    \n",
    "    studyId = ogr.FieldDefn(\"studyID\", ogr.OFTString)\n",
    "    studyId.SetWidth(20)\n",
    "    layer.CreateField(studyId)\n",
    "    f = ogr.FieldDefn(\"filename\", ogr.OFTString)\n",
    "    f.SetWidth(100)\n",
    "    layer.CreateField(f)\n",
    "    d = ogr.FieldDefn(\"doi\", ogr.OFTString)\n",
    "    d.SetWidth(100)\n",
    "    layer.CreateField(d)\n",
    "    i = ogr.FieldDefn(\"invstgtrs\", ogr.OFTString)\n",
    "    i.SetWidth(150)\n",
    "    layer.CreateField(i)\n",
    "    layer.CreateField(ogr.FieldDefn(\"lat\", ogr.OFTReal))\n",
    "    layer.CreateField(ogr.FieldDefn(\"lon\", ogr.OFTReal))\n",
    "    sn = ogr.FieldDefn(\"sitename\", ogr.OFTString)\n",
    "    sn.SetWidth(150)\n",
    "    layer.CreateField(sn)\n",
    "    spc = ogr.FieldDefn(\"sppCom\", ogr.OFTString)\n",
    "    spc.SetWidth(150)\n",
    "    layer.CreateField(spc)\n",
    "    sps = ogr.FieldDefn(\"sppSci\", ogr.OFTString)\n",
    "    sps.SetWidth(150)\n",
    "    layer.CreateField(sps)\n",
    "    scode = ogr.FieldDefn(\"sppCode\", ogr.OFTString)\n",
    "    scode.SetWidth(10)\n",
    "    layer.CreateField(scode)\n",
    "    layer.CreateField(ogr.FieldDefn(\"earliest\", ogr.OFTInteger))\n",
    "    layer.CreateField(ogr.FieldDefn(\"mostRecent\", ogr.OFTInteger))\n",
    "    studycode = ogr.FieldDefn(\"studyCode\", ogr.OFTString)\n",
    "    studycode.SetWidth(20)\n",
    "    layer.CreateField(studycode)\n",
    "    noaap = ogr.FieldDefn(\"noaaPage\", ogr.OFTString)\n",
    "    noaap.SetWidth(150)\n",
    "    layer.CreateField(noaap)\n",
    "\n",
    "    n = 0\n",
    "    while n < len(data['features']):\n",
    "        # create the feature\n",
    "        feature = ogr.Feature(layer.GetLayerDefn())\n",
    "        \n",
    "        # Set the attributes using the values from the delimited text file\n",
    "        feature.SetField(\"studyID\", data['features'][n]['properties'][\"study_ID\"])\n",
    "        feature.SetField(\"filename\", data['features'][n]['properties'][\"orig_filename\"])\n",
    "        feature.SetField(\"doi\", data['features'][n]['properties'][\"doi\"])\n",
    "        feature.SetField(\"invstgtrs\", data['features'][n]['properties'][\"investigators\"])\n",
    "        feature.SetField(\"lat\", float(data['features'][n]['properties'][\"lat\"]))\n",
    "        feature.SetField(\"lon\", float(data['features'][n]['properties'][\"lon\"]))\n",
    "        feature.SetField(\"sitename\", data['features'][n]['properties'][\"site_name\"])\n",
    "        feature.SetField(\"sppCom\", data['features'][n]['properties'][\"species_name_com\"][0])\n",
    "        feature.SetField(\"sppSci\", data['features'][n]['properties'][\"species_name_sci\"])\n",
    "        feature.SetField(\"sppCode\", data['features'][n]['properties'][\"species_code\"])\n",
    "        feature.SetField(\"earliest\", int(data['features'][n]['properties'][\"earliest_year\"]))\n",
    "        feature.SetField(\"mostRecent\", int(data['features'][n]['properties'][\"most_recent_year\"]))\n",
    "        feature.SetField(\"studyCode\", data['features'][n]['properties'][\"study_code\"])\n",
    "        feature.SetField(\"noaaPage\", data['features'][n]['properties'][\"noaa_online_resource_page\"])\n",
    "\n",
    "        point = ogr.Geometry(ogr.wkbPoint)\n",
    "        point.AddPoint(float(data['features'][n]['geometry']['coordinates'][0]), float(data['features'][n]['geometry']['coordinates'][1]))\n",
    "\n",
    "        # Set the feature geometry using the polygon\n",
    "        feature.SetGeometry(point)\n",
    "\n",
    "        # Create the feature in the layer (shapefile)\n",
    "        layer.CreateFeature(feature)\n",
    "\n",
    "        # Dereference the feature\n",
    "        feature = None\n",
    "        n+=1\n",
    "    data_source = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geojson_to_shapefile(\"C:/Users/Jacob/Projects/itrdb/data/itrdb.geojson\", \"C:/Users/Jacob/Projects/itrdb/data/itrdb.shp\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
